import streamlit as st
import os
import google.generativeai as genai
import pandas as pd
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

# --- Constants ---
# CSV_FILE_PATH = os.path.join(os.path.dirname(__file__), "all_syllabus_with_overview.csv") # ã“ã“ã‚’ä¿®æ­£
CSV_FILE_PATH = os.path.join(os.path.dirname(__file__), "..","data", "all_syllabus_with_overview.csv")
GENERATIVE_MODEL = 'gemini-2.5-flash'

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
# SYSTEM_PROMPT_PATH = os.path.join(os.path.dirname(__file__), "prompts", "system_prompt.txt")
SYSTEM_PROMPT_PATH = os.path.join(os.path.dirname(__file__), "..", "syllabus_search", "prompts", "system_prompt.txt")

# --- Utility Functions ---
def load_prompt_from_file(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        st.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
        st.stop()
    except Exception as e:
        st.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

def get_api_key():
    """ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯Streamlit secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã™ã‚‹"""
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        try:
            api_key = st.secrets["GEMINI_API_KEY"]
        except (FileNotFoundError, KeyError):
            st.error("GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯Streamlitã®secretsã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            st.stop() # APIã‚­ãƒ¼ãŒãªã„å ´åˆã¯ã‚¢ãƒ—ãƒªã‚’åœæ­¢
    return api_key

@st.cache_data
def load_all_syllabus_data(csv_path):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å…¨ã¦ã®ã‚·ãƒ©ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        df = pd.read_csv(csv_path)
        required_cols = ['subject_name', 'overview', 'detail_url']
        if not all(col in df.columns for col in required_cols):
            st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã«å¿…è¦ãªã‚«ãƒ©ãƒ  ({', '.join(required_cols)}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            st.stop()
        df = df.fillna('')
        return df
    except FileNotFoundError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ã‚·ãƒ©ãƒã‚¹CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        st.stop()
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

def format_syllabuses_for_llm(df):
    """DataFrameã®ã‚·ãƒ©ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’LLMã«æ¸¡ã›ã‚‹å½¢å¼ã«æ•´å½¢ã™ã‚‹"""
    return "---\n".join(
        f"ç§‘ç›®å: {row['subject_name']}\næ¦‚è¦: {row['overview']}\nç§‘ç›®URL: {row['detail_url']}"
        for index, row in df.iterrows()
    )

# --- LangChain Setup ---
def create_langchain_chain(api_key, all_syllabuses_text):
    """LangChainã®ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆã™ã‚‹"""
    # LLM
    llm = ChatGoogleGenerativeAI(model=GENERATIVE_MODEL, google_api_key=api_key, stream=True)

    # Prompt
    system_prompt_template = load_prompt_from_file(SYSTEM_PROMPT_PATH)
    system_prompt = system_prompt_template.format(all_syllabuses_text=all_syllabuses_text)

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{question}"),
    ])

    # Chain
    chain = prompt | llm
    return chain

# --- Streamlit App ---
st.set_page_config(page_title="ã‚·ãƒ©ãƒã‚¹AIãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ“")
st.title("ğŸ“ ã‚·ãƒ©ãƒã‚¹æ¤œç´¢")
st.write("ãƒ ã‚µãƒ“é€šä¿¡ã®ã‚·ãƒ©ãƒã‚¹ã‚’ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§æ¤œç´¢ã§ãã¾ã™ã€‚")
st.warning("æ³¨æ„:å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã«é”ã—ã€ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

# ãƒšãƒ¼ã‚¸ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã¨ãã«ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ
if "last_page_loaded" not in st.session_state or st.session_state.last_page_loaded != "syllabus_chat_page":
    st.session_state.chat_history = []
    st.session_state.last_page_loaded = "syllabus_chat_page"

# --- Initialization ---
try:
    api_key = get_api_key()
    genai.configure(api_key=api_key)
except Exception as e:
    st.error(f"APIã‚­ãƒ¼ã®è¨­å®šä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()

all_syllabus_df = load_all_syllabus_data(CSV_FILE_PATH)
all_syllabuses_formatted_text = format_syllabuses_for_llm(all_syllabus_df)

# LangChainã®ãƒã‚§ãƒ¼ãƒ³ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ç®¡ç†
if "chain" not in st.session_state:
    st.session_state.chain = create_langchain_chain(api_key, all_syllabuses_formatted_text)

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- Chat Interface ---
# Display chat messages from history
for message in st.session_state.chat_history:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.markdown(message.content)
    elif isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(message.content)

# Accept user input
if user_question := st.chat_input("ã©ã®ã‚ˆã†ãªæˆæ¥­ã‚’æ¢ã—ã¾ã™ã‹ï¼Ÿ"):
    # Add user message to history and display
    st.session_state.chat_history.append(HumanMessage(content=user_question))
    with st.chat_message("user"):
        st.markdown(user_question)

    # Generate and display AI response
    with st.chat_message("assistant"):
        with st.spinner("AIãŒè€ƒãˆã¦ã„ã¾ã™..."):
            try:
                response_stream = st.session_state.chain.stream({
                    "chat_history": st.session_state.chat_history,
                    "question": user_question
                })
                full_response = st.write_stream(response_stream)
                st.session_state.chat_history.append(AIMessage(content=full_response))
            except Exception as e:
                st.error(f"å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                # Remove the last user message if AI fails
                if st.session_state.chat_history: # å±¥æ­´ãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
                    st.session_state.chat_history.pop()
